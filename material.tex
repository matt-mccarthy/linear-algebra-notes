\section{Vector Spaces}

\begin{definition}[Vector Space]
	A \textit{vector space} $V$ over a field $\FF$ is a set with two binary operations, $+:V\times V\rightarrow V$ and $\cdot:V\times\FF\rightarrow V$ such that all of the following hold.
	\begin{enumerate}
		\item For all $x,y\in V$, $x+y=y+x$. (Additive Commutativity)
		\item For all $x,y,z\in V$, $x+(y+z)=(x+y)+z$. (Additive Associativity)
		\item There exists an element, denoted 0, in $V$ such that for all $x\in V$, $x+0=x$.
		\item For each $x\in V$ there exists a $y\in V$, denoted $-x$, such that $x+y=0$.
		\item For all $x\in V$, $1x=x$.
		\item For all $a,b\in\FF$ and $x\in V$, $a(bx)=(ab)x$.
		\item For all $a\in\FF$ and $x,y\in V$, $a(x+y)=ax+ay$.
		\item For all $a,b\in\FF$ and $x\in V$, $(a+b)x=ax+bx$.
	\end{enumerate}
	Furthermore, $x+y$ is called the \textit{sum of $x$ and $y$} while $ax$ is called the \textit{product of $x$ and $a$}.
	Moreover, each $x\in V$ is called a \textit{vector} and each $a\in\FF$ is called a \textit{scalar}.
\end{definition}

\begin{definition}[$n$-tuple]
	An object of the form $(a_1,a_2,\ldots,a_n)$ where $a_j\in\FF$ for all $1\leq j\leq n$, is called an \textit{$n$-tuple}.
\end{definition}

\begin{example}
	Let $\FF$ be a field and $n\in\NN$, then $\FF^n=\set{(a_1,a_2,\ldots,a_n)| a_j\in\FF \forall 1\leq j\leq n}$ forms a vector space under component-wise addition and multiplication as defined below for $(a_1,a_2,\ldots ,a_n),(b_1,b_2,\ldots,b_n)\in\FF^n$ and $k\in\FF$.
	\begin{align*}
		(a_1,a_2,\ldots ,a_n)+(b_1,b_2,\ldots,b_n)&=(a_1+b_1,a_2+b_2,\ldots,a_n+b_n)\\
		k(a_1,a_2,\ldots ,a_n)&=(ka_1,ka_2,\ldots,ka_n)
	\end{align*}
	Furthermore, it said that
	\[
		(a_1,a_2,\ldots ,a_n)=(b_1,b_2,\ldots,b_n)
	\]
	if and only if $a_j=b_j$ for all $1\leq j\leq n$.
\end{example}
\begin{proof}
	$\FF^n$ is a vector space trivially from the fact that $\FF$ is a field.
\end{proof}

\begin{definition}[Matrix]
	Let $\FF$ be a field and $m,n\in\NN$, then an \textit{$m\times n$ matrix} with entries from $\FF$ is a rectangular array of the form
	\[
		A=
		\begin{pmatrix}
			a_{1,1} & a_{1,2} & \ldots & a_{1,n}\\
			a_{2,1} & a_{2,2} & \ldots & a_{2,n}\\
			\vdots & \vdots & \ddots & \vdots\\
			a_{m,1} & a_{m,2} & \ldots & a_{m,n}
		\end{pmatrix}
	\]
	where $a_{i,j}\in\FF$ for all $1\leq i \leq m$ and $1\leq j \leq n$.
	The entries $(a_{i,1},a_{i,2},\ldots,a_{i,n})$ is called the \textit{$i$th row} of the matrix and is a row vector in $\FF^n$.
	The entries $(a_{1,j},a_{2,j},\ldots,a_{m,j})$ is called the \textit{$j$th column} of the matrix and is a column vector in $\FF^n$.
	We denote the entry on the $i$th row and $j$th column as $A_{i,j}$.
	Furthermore, two $m\times n$ matrices, $A$ and $B$, are equal if and only if $A_{i,j}=B_{i,j}$ for all $1\leq i\leq m$ and $1\leq j\leq n$; we denote this by $A=B$.
	Moreover, if $n=m$ we say that $A$ is a \textit{square matrix}.
	Lastly, we denote the set of $m\times n$ matrices over $\FF$ as $M_{m\times n}(\FF)$.
\end{definition}

\begin{example}
	Let $\FF$ be a field and $m,n\in\NN$, then $M_{m\times n}(\FF)$ is a vector space over $\FF$ under the following operations for $A,B\in M_{m\times n}(\FF)$ and $k\in\FF$.
	\begin{align*}
		(A+B)_{i,j}&=A_{i,j}+B_{i,j}\\
		(kA)_{i,j}&=kA_{i,j}
	\end{align*}
\end{example}
\begin{proof}
	The proof is trivial from the fact that we operating on multiple copies of a field.
\end{proof}

\begin{example}
	Let $S$ be a nonempty set and let $\FF$ be a field and let $\mathscr{F}(S,\FF)$ denote the set of all functions from $S$ into $\FF$.
	Two elements $f,g\in\mathscr{F}(S,\FF)$ are equal if and only if $f(s)=g(s)$ for all $s\in S$.
	Then $\mathscr{F}(S,\FF)$ is a vector space under the following operations for $f,g\in\mathscr{F}(S,\FF)$ and $k\in\FF$.
	\begin{align*}
		(f+g)(s)&=f(s)+g(s)\\
		(kf)(s)&=k\brac{f(s)}
	\end{align*}
\end{example}
\begin{proof}
	The proof is trivial because all operations are done inside the field, and thus the space inherits the structure from $\FF$.
\end{proof}

\begin{definition}[Polynomial Ring]
	Let $\FF$ be a field.
	Then the \textit{ring of polynomials in an indeterminate $x$ over $\FF$}, denoted $\FF[x]$ is defined as
	\[
		\FF[x] := \set{\sum_{i=0}^n a_i x^i | n\in\NN, (a_0,a_1,\ldots,a_n)\in\FF^n, a_n\neq 0}.
	\]
	Additionally, we define $x^0=1$.
	Moreover, for each $p=\sum_{i=0}^n p_ix^i\in\FF[x]$, the \textit{degree of $p$}, denoted $\deg p$, is $n$.
	Furthermore, if $p=0$, that is $p_n=p_{n-1}=\ldots=p_0=0$, then $p$ is called the \textit{zero polynomial} and $\deg p = -1$ or $\deg p =-\infty$ depending on convention.
	If $\deg p=0$, then we say $p$ is a \textit{constant polynomial}.
	Lastly, $\FF[x]$ forms a ring under the following operations where $p,q\in\FF[x]$ and without loss of generality assume, $\deg p \geq\deg q$.
	\begin{align*}
		p+q &=\sum_{i=0}^{\deg q} (p_i+q_i) +\sum_{i=\deg q + 1}^{\deg p} p_i\\
		p q &= \sum_{k=0}^{\deg p \cdot \deg q} \sum_{i+j=k} p_iq_j
	\end{align*}
\end{definition}
\begin{example}
	Let $\FF$ be a field, then $\FF[x]$ is a vector space over $\FF$ under polynomial addition and scalar multiplication by constant polynomials.
\end{example}
\begin{proof}
	Since $\FF[x]$ is a ring, it is closed under addition.
	Since constant polynomials are polynomials, it is closed under scalar multiplication.
	Since $\FF[x]$ is a ring, addition is commutative and associative.
	Moreover the zero polynomial is the additive identity and likewise serves as the zero vector.
	Since $\FF[x]$ is a ring, each $p\in\FF[x]$ has a unique $-p\in\FF[x]$ such that $p+(-p)=0$.
	The constant polynomial $1$ is the multiplicative identity in the ring and serves as the identity in the vector space.
	Furthermore, multiplication is associative and distributes over addition because $\FF[x]$ is, indeed, a ring.
\end{proof}

\begin{proposition}
	The zero vector in any vector space $V$ is unique.
\end{proposition}
\begin{proof}
	Assume there exists two zero vectors in $V$ denoted $0_1$ and $0_2$.
	Then $v+0_1=v$ and $v+0_2=v$ for all $v\in V$.
	Therefore it is true that
	\[
		0_2 = 0_2+0_1 = 0_1 + 0_2 = 0_1
	\]
	and thus these identities are in fact the same.
\end{proof}
\begin{proposition}
	Let $V$ be a vector space and let $v\in V$, then there exists a unique $u\in V$ such that $v+u=0$.
\end{proposition}
\begin{proof}
	Assume $v$ has two inverses, namely $u_1$ and $u_2$.
	Then $v+u_1=0$ and $v+u_2=0$.
	Therefore,
	\[
		v+u_1+u_2=0+u_2=u_2
	\]
	and
	\[
		v+u_1+u_2=v+u_2+u_1=0+u_1=u_1.
	\]
	Ergo, $u_1=u_2$ and the inverse of $v$ is unique.
\end{proof}
